{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from standard_functions import *\n",
    "path = os.getcwd()\n",
    "data_path = os.path.join(os.path.dirname(path), 'Data') \n",
    "\n",
    "BloombergData = pd.read_csv(data_path + \"/BloombergData_Swap_Features.csv\")\n",
    "preData = pd.read_csv(data_path + \"/TestData_Swap_Features_pre.csv\")\n",
    "postData = pd.read_csv(data_path + \"/TestData_Swap_Features_post.csv\")\n",
    "\n",
    "insample = np.array(BloombergData.iloc[:,2:].reset_index(drop=True)) \n",
    "insample_scaled = [x/100 for x in insample]\n",
    "insample_tensor = torch.from_numpy(np.float32(insample_scaled))\n",
    "\n",
    "X_train1, X_val1 = train_validation_split(BloombergData.reset_index(drop=True), 0.1) \n",
    "X_train2  = np.array(X_train1.iloc[:,2:].reset_index(drop=True)) \n",
    "X_train_scaled = [x/100 for x in X_train2]\n",
    "X_train_tensor = torch.from_numpy(np.float32(X_train_scaled))\n",
    "\n",
    "X_val2  = np.array(X_val1.iloc[:,2:].reset_index(drop=True)) \n",
    "X_val_scaled = [x/100 for x in X_val2]\n",
    "X_val_tensor = torch.from_numpy(np.float32(X_val_scaled))\n",
    "\n",
    "preX_test2  = np.array(preData.iloc[:,2:].reset_index(drop=True)) \n",
    "preX_test_scaled = [x/100 for x in preX_test2]\n",
    "preX_test_tensor = torch.from_numpy(np.float32(preX_test_scaled))\n",
    "\n",
    "postX_test2  = np.array(postData.iloc[:,2:].reset_index(drop=True)) \n",
    "postX_test_scaled = [x/100 for x in postX_test2]\n",
    "postX_test_tensor = torch.from_numpy(np.float32(postX_test_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(8, 2, bias = False)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 10, bias = False),\n",
    "            centered_softmax(),\n",
    "            nn.Linear(10, 1, bias = False)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Encoder\n",
    "        x = self.encoder(x)  #Nx2 \n",
    "\n",
    "        # Maturity \n",
    "        mat = torch.arange(1, 31, dtype=torch.float32).repeat(len(x)) # length N*30 array of 1-30,1-30 and so on N times \n",
    "\n",
    "        x1 = x.unsqueeze(1).expand(-1, 30, -1).reshape(-1, 2)         # Nx30x2 then reshaped to N*30x2 \"reshape(-1, 3)\" 3 is for 3 factor. \n",
    "                                                                      # If 2-factor, then .reshape(-1, 2)\n",
    "        result = torch.cat([x1, mat.unsqueeze(1)], dim=1)             # N*30x3\n",
    "                                                                        \n",
    "        # Decoder --> gives y for all maturities \n",
    "        y = self.decoder(result).reshape(len(x), 30)\n",
    "\n",
    "        # Transformations: y->p->s: \n",
    "        p = torch.exp(-mat.reshape(y.shape[0],30) * y)\n",
    "\n",
    "        p_cumsum = torch.cumsum(p, dim=1)  # N, 30\n",
    "\n",
    "        s = (1 - p) / p_cumsum  # N, 30\n",
    "        \n",
    "        return s, p, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "\n",
    "\n",
    "# # Initialize autoencoder, MSE loss, and optimizer\n",
    "# model = Autoencoder()   \n",
    "# model = Autoencoder()   \n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# lr_sched = LR_Scheduler(optimizer, percentage = 0.9, interval = 50)\n",
    "\n",
    "# # Training\n",
    "# num_epochs = 3336\n",
    "# batch_size = 32\n",
    "# data_loader = torch.utils.data.DataLoader(X_train_tensor, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# swap_mats = [1, 2, 3, 5, 10, 15, 20, 30]\n",
    "# swap_mats0 = [i-1 for i in swap_mats]\n",
    "\n",
    "# losses_list = []\n",
    "# vallosses_list = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in data_loader:\n",
    "        \n",
    "#         # Forward pass\n",
    "#         reconstructed, p_final, y_final = model(batch)\n",
    "\n",
    "#         s_final = reconstructed[:, swap_mats0]\n",
    "        \n",
    "#         loss = criterion(s_final, batch)\n",
    "        \n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward(retain_graph=True)\n",
    "#         optimizer.step()\n",
    "#     lr_sched.step()\n",
    "\n",
    "#     N = len(X_val_tensor)    \n",
    "#     reconstructed, p_final, y_final = model(X_val_tensor)\n",
    "#     s_final = reconstructed[:, swap_mats0]\n",
    "#     loss_val = criterion(s_final, X_val_tensor)\n",
    "\n",
    "#     N = len(X_train_tensor)    \n",
    "#     reconstructed, p_final, y_final = model(X_train_tensor)\n",
    "#     s_final = reconstructed[:, swap_mats0]\n",
    "#     loss_train = criterion(s_final, X_train_tensor)\n",
    "\n",
    "#         # append relevant data\n",
    "#     vallosses_list.append(loss_val.item())\n",
    "#     losses_list.append(loss_train.item())\n",
    "        \n",
    "#     if (epoch + 1) % 100 == 0:\n",
    "#         print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss train: {loss_train.item():.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"2factor_FIAE\"\n",
    "# torch.save(model.state_dict(), f\"models/{name}.pth\")\n",
    "# print(f\"Model saved successfully as models/{name}.pth\")\n",
    "model2 = Autoencoder()       # Ensure Autoencoder class is defined\n",
    "model2.load_state_dict(torch.load(f\"models/{name}.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
